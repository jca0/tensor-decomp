{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_data_gmm(d=20, k=3, sigma=0.1, rho=0, n_samples=10000, var_scale=0.01):\n",
        "    # Generate correlated component means (analogous to factor matrices)\n",
        "    if rho == 0:\n",
        "        means = np.random.randn(d, k)\n",
        "    else:\n",
        "        Sigma = rho * np.ones((k, k)) + (1 - rho) * np.eye(k)\n",
        "        L = np.linalg.cholesky(Sigma)\n",
        "        means = np.random.randn(d, k) @ L\n",
        "    # Normalize columns (like in original)\n",
        "    norm = lambda X: np.maximum(np.linalg.norm(X, axis=0, keepdims=True), 1e-10)\n",
        "    means = means / norm(means)\n",
        "    \n",
        "    # GMM parameters: equal weights, small variance for low-rank moment approximation\n",
        "    weights = np.ones(k) / k\n",
        "    covariances = [var_scale * np.eye(d) for _ in range(k)]  # Spherical, small var\n",
        "    \n",
        "    # Generate multivariate samples\n",
        "    z = np.random.choice(k, size=n_samples, p=weights)\n",
        "    X = np.zeros((n_samples, d))\n",
        "    for i in range(n_samples):\n",
        "        X[i] = np.random.multivariate_normal(means[:, z[i]], covariances[z[i]])\n",
        "    \n",
        "    # Compute empirical third-order moment tensor (T_noisy)\n",
        "    T_noisy = np.zeros((d, d, d))\n",
        "    for i in range(n_samples):\n",
        "        x = X[i]\n",
        "        T_noisy += np.einsum('p,q,r->pqr', x, x, x) / n_samples\n",
        "    \n",
        "    # Compute true low-rank third-order moment (approx ignoring var terms, since small)\n",
        "    T = np.zeros((d, d, d))\n",
        "    for j in range(k):\n",
        "        mu = means[:, j]\n",
        "        T += weights[j] * np.einsum('p,q,r->pqr', mu, mu, mu)\n",
        "    \n",
        "    # Add extra dense Gaussian noise to T_noisy (like original)\n",
        "    E = np.random.randn(d, d, d)\n",
        "    if fro_norm(T) > 0:\n",
        "        E = E / fro_norm(E) * fro_norm(T) * sigma\n",
        "    T_noisy += E\n",
        "    \n",
        "    # Return in expected format (symmetric, so A=B=C)\n",
        "    return T, T_noisy, means, means, means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_data_hmm(d=20, k=3, sigma=0.1, rho=0.5, n_steps=100000, var_scale=0.01):\n",
        "    # Ground truth: k states, emission means (d x k)\n",
        "    means = np.random.randn(d, k)\n",
        "    norm = lambda X: np.maximum(np.linalg.norm(X, axis=0, keepdims=True), 1e-10)\n",
        "    means = means / norm(means)\n",
        "    \n",
        "    # Transition matrix with rho as diagonal (persistence/correlation)\n",
        "    off_diag = (1 - rho) / (k - 1) if k > 1 else 0\n",
        "    trans = off_diag * np.ones((k, k))\n",
        "    np.fill_diagonal(trans, rho)\n",
        "    \n",
        "    # Initial prob, covariances small\n",
        "    init_prob = np.ones(k) / k\n",
        "    covariances = [var_scale * np.eye(d) for _ in range(k)]\n",
        "    \n",
        "    # Generate latent states\n",
        "    states = np.zeros(n_steps, dtype=int)\n",
        "    states[0] = np.random.choice(k, p=init_prob)\n",
        "    for t in range(1, n_steps):\n",
        "        states[t] = np.random.choice(k, p=trans[states[t-1]])\n",
        "    \n",
        "    # Generate multivariate observations\n",
        "    X = np.zeros((n_steps, d))\n",
        "    for t in range(n_steps):\n",
        "        X[t] = np.random.multivariate_normal(means[:, states[t]], covariances[states[t]])\n",
        "    \n",
        "    # Compute empirical third-order cross-moment tensor (asymmetric)\n",
        "    T_noisy = np.zeros((d, d, d))\n",
        "    for t in range(n_steps - 2):\n",
        "        T_noisy += np.einsum('p,q,r->pqr', X[t], X[t+1], X[t+2]) / (n_steps - 2)\n",
        "    \n",
        "    # Compute true tensor analytically: sum pi_i * trans_ij * trans_jl * mu_i ⊗ mu_j ⊗ mu_l\n",
        "    # First, stationary dist pi (solve pi = pi @ trans)\n",
        "    eigvals, eigvecs = np.linalg.eig(trans.T)\n",
        "    stationary = eigvecs[:, np.argmin(np.abs(eigvals - 1))].real\n",
        "    pi = stationary / stationary.sum()\n",
        "    \n",
        "    T = np.zeros((d, d, d))\n",
        "    for i in range(k):\n",
        "        for j in range(k):\n",
        "            for l in range(k):\n",
        "                contrib = pi[i] * trans[i, j] * trans[j, l]\n",
        "                T += contrib * np.einsum('p,q,r->pqr', means[:, i], means[:, j], means[:, l])\n",
        "    \n",
        "    # Add extra noise\n",
        "    E = np.random.randn(d, d, d)\n",
        "    if fro_norm(T) > 0:\n",
        "        E = E / fro_norm(E) * fro_norm(T) * sigma\n",
        "    T_noisy += E\n",
        "    \n",
        "    # Return (factors approximated as means; decomposition recovers related matrices)\n",
        "    return T, T_noisy, means, means, means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import eig, pinv\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def khatri_rao(P, Q):\n",
        "    d1, k = P.shape\n",
        "    d2, _ = Q.shape\n",
        "    return np.hstack([np.kron(P[:, i], Q[:, i])[:, np.newaxis] for i in range(k)])\n",
        "\n",
        "def reconstruct_tensor(A, B, C):\n",
        "    d, k = A.shape\n",
        "    T = np.zeros((d, d, d))\n",
        "    for i in range(k):\n",
        "        T += np.outer(A[:, i], B[:, i])[:, :, np.newaxis] * C[:, i]\n",
        "    return T\n",
        "\n",
        "def fro_norm(X):\n",
        "    return np.sqrt(np.sum(X**2))\n",
        "\n",
        "def reconstruction_error(true_T, hat_T):\n",
        "    return fro_norm(true_T - hat_T) / fro_norm(true_T)\n",
        "\n",
        "def factor_recovery_error(true_F, hat_F):\n",
        "    d, k = true_F.shape\n",
        "    true_norm = true_F / np.linalg.norm(true_F, axis=0)\n",
        "    hat_norm = hat_F / np.linalg.norm(hat_F, axis=0)\n",
        "    cos_matrix = np.abs(true_norm.T @ hat_norm)\n",
        "    cost = -cos_matrix\n",
        "    row_ind, col_ind = linear_sum_assignment(cost)\n",
        "    mean_cos = np.mean(cos_matrix[row_ind, col_ind])\n",
        "    return mean_cos  # Higher is better; for error, could use 1 - mean_cos if desired\n",
        "\n",
        "def jennrich(T_noisy, k):\n",
        "    d = T_noisy.shape[0]\n",
        "    u = np.random.randn(d)\n",
        "    v = np.random.randn(d)\n",
        "    M1 = np.sum(u[:, np.newaxis, np.newaxis] * T_noisy, axis=2)\n",
        "    M2 = np.sum(v[:, np.newaxis, np.newaxis] * T_noisy, axis=2)\n",
        "    try:\n",
        "        vals, vl, vr = eig(M1, M2, left=True, right=True)\n",
        "        if np.any(np.imag(vals) != 0):\n",
        "            return None, None, None\n",
        "        vl = np.real(vl)\n",
        "        vr = np.real(vr)\n",
        "        A_hat = np.linalg.inv(vl).T\n",
        "        B_hat = np.linalg.inv(vr).T\n",
        "        T3 = np.transpose(T_noisy, (2, 0, 1)).reshape(d, d * d)\n",
        "        kr = khatri_rao(A_hat, B_hat)\n",
        "        C_hat = T3 @ pinv(kr.T)\n",
        "        return A_hat, B_hat, C_hat\n",
        "    except:\n",
        "        return None, None, None\n",
        "\n",
        "def cp_als(T, k, max_iter=50, tol=1e-4):\n",
        "    d = T.shape[0]\n",
        "    A = np.random.randn(d, k)\n",
        "    B = np.random.randn(d, k)\n",
        "    C = np.random.randn(d, k)\n",
        "    norm = lambda X: np.maximum(np.linalg.norm(X, axis=0, keepdims=True), 1e-10)\n",
        "    A = A / norm(A)\n",
        "    B = B / norm(B)\n",
        "    C = C / norm(C)\n",
        "    for _ in range(max_iter):\n",
        "        # Update A\n",
        "        kr = khatri_rao(B, C)\n",
        "        T1 = T.reshape(d, d * d)\n",
        "        A = T1 @ kr @ pinv(kr.T @ kr)\n",
        "        A = A / norm(A)\n",
        "        # Update B\n",
        "        kr = khatri_rao(A, C)\n",
        "        T2 = np.transpose(T, (1, 0, 2)).reshape(d, d * d)\n",
        "        B = T2 @ kr @ pinv(kr.T @ kr)\n",
        "        B = B / norm(B)\n",
        "        # Update C\n",
        "        kr = khatri_rao(A, B)\n",
        "        T3 = np.transpose(T, (2, 0, 1)).reshape(d, d * d)\n",
        "        C = T3 @ kr @ pinv(kr.T @ kr)\n",
        "        C = C / norm(C)\n",
        "    return A, B, C\n",
        "\n",
        "def ortho_als(T, k, max_iter=50, tol=1e-4):\n",
        "    \"\"\"\n",
        "    Ortho-ALS for CP decomposition.\n",
        "    Adds an orthogonalization (QR) step after each factor update.\n",
        "\n",
        "    Args:\n",
        "        T: d x d x d tensor\n",
        "        k: rank\n",
        "        max_iter: number of ALS iterations\n",
        "        tol: stopping tolerance (optional, usually not needed)\n",
        "\n",
        "    Returns:\n",
        "        A, B, C: factor matrices (d x k)\n",
        "    \"\"\"\n",
        "    d = T.shape[0]\n",
        "\n",
        "    # Random initialization\n",
        "    A = np.random.randn(d, k)\n",
        "    B = np.random.randn(d, k)\n",
        "    C = np.random.randn(d, k)\n",
        "\n",
        "    # Normalize columns\n",
        "    def normalize(X):\n",
        "        return X / np.maximum(np.linalg.norm(X, axis=0, keepdims=True), 1e-10)\n",
        "\n",
        "    A = normalize(A)\n",
        "    B = normalize(B)\n",
        "    C = normalize(C)\n",
        "\n",
        "    # Unfoldings\n",
        "    T1 = T.reshape(d, d * d)\n",
        "    T2 = np.transpose(T, (1, 0, 2)).reshape(d, d * d)\n",
        "    T3 = np.transpose(T, (2, 0, 1)).reshape(d, d * d)\n",
        "\n",
        "    for it in range(max_iter):\n",
        "\n",
        "        # --- Update A ---\n",
        "        kr = khatri_rao(B, C)        # (d*d) x k\n",
        "        A = T1 @ kr @ pinv(kr.T @ kr)\n",
        "        # Ortho step: QR with economic mode\n",
        "        A, _ = np.linalg.qr(A)\n",
        "        A = A[:, :k]                 # take first k orthonormal cols\n",
        "        A = normalize(A)\n",
        "\n",
        "        # --- Update B ---\n",
        "        kr = khatri_rao(A, C)\n",
        "        B = T2 @ kr @ pinv(kr.T @ kr)\n",
        "        B, _ = np.linalg.qr(B)\n",
        "        B = B[:, :k]\n",
        "        B = normalize(B)\n",
        "\n",
        "        # --- Update C ---\n",
        "        kr = khatri_rao(A, B)\n",
        "        C = T3 @ kr @ pinv(kr.T @ kr)\n",
        "        C, _ = np.linalg.qr(C)\n",
        "        C = C[:, :k]\n",
        "        C = normalize(C)\n",
        "\n",
        "    return A, B, C\n",
        "\n",
        "def generate_data(d, k, sigma, rho=0):\n",
        "    A = np.random.randn(d, k)\n",
        "    B = np.random.randn(d, k)\n",
        "    if rho == 0:\n",
        "        C = np.random.randn(d, k)\n",
        "    else:\n",
        "        Sigma = rho * np.ones((k, k)) + (1 - rho) * np.eye(k)\n",
        "        L = np.linalg.cholesky(Sigma)\n",
        "        C = np.random.randn(d, k) @ L\n",
        "    norm = lambda X: np.maximum(np.linalg.norm(X, axis=0, keepdims=True), 1e-10)\n",
        "    A = A / norm(A)\n",
        "    B = B / norm(B)\n",
        "    C = C / norm(C)\n",
        "    T = reconstruct_tensor(A, B, C)\n",
        "    E = np.random.randn(d, d, d)\n",
        "    if fro_norm(T) > 0:\n",
        "        E = E / fro_norm(E) * fro_norm(T) * sigma\n",
        "    T_noisy = T + E\n",
        "    return T, T_noisy, A, B, C\n",
        "\n",
        "# Experiment 1: Bad Conditioning Test\n",
        "def experiment1(d=20, k=3, sigma=0.1, num_reps=50):\n",
        "    rhos = np.linspace(0, 0.99, 10)\n",
        "    jenn_rec = []\n",
        "    als_rec = []\n",
        "    ortho_rec = []\n",
        "    jenn_fac = []\n",
        "    als_fac = []\n",
        "    ortho_fac = []\n",
        "    for rho in rhos:\n",
        "        rec_j, fac_j, rec_a, fac_a, rec_o, fac_o = [], [], [], [], [], []\n",
        "        for _ in range(num_reps):\n",
        "            T, T_noisy, A_true, B_true, C_true = generate_data_gmm(d, k, sigma, rho)\n",
        "            # Jennrich\n",
        "            A_hat, B_hat, C_hat = jennrich(T_noisy, k)\n",
        "            if A_hat is not None:\n",
        "                hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "                rec_j.append(reconstruction_error(T, hat_T))\n",
        "                fac_j.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "            # ALS\n",
        "            A_hat, B_hat, C_hat = cp_als(T_noisy, k)\n",
        "            hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "            rec_a.append(reconstruction_error(T, hat_T))\n",
        "            fac_a.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "            # Ortho-ALS\n",
        "            A_hat, B_hat, C_hat = ortho_als(T_noisy, k)\n",
        "            hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "            rec_o.append(reconstruction_error(T, hat_T))\n",
        "            fac_o.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "        jenn_rec.append(np.mean(rec_j) if rec_j else np.nan)\n",
        "        als_rec.append(np.mean(rec_a))\n",
        "        ortho_rec.append(np.mean(rec_o))\n",
        "        jenn_fac.append(np.mean(fac_j) if fac_j else np.nan)\n",
        "        als_fac.append(np.mean(fac_a))\n",
        "        ortho_fac.append(np.mean(fac_o))\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    ax1.plot(rhos, jenn_rec, label='Jennrich Rec Err')\n",
        "    ax1.plot(rhos, als_rec, label='ALS Rec Err')\n",
        "    ax1.plot(rhos, ortho_rec, label='Ortho-ALS Rec Err')\n",
        "    ax1.legend()\n",
        "    ax1.set_xlabel('rho')\n",
        "    ax1.set_ylabel('Reconstruction Error')\n",
        "    ax1.set_title('Reconstruction Error vs rho')\n",
        "\n",
        "    ax2.plot(rhos, jenn_fac, label='Jennrich Fac Sim')\n",
        "    ax2.plot(rhos, als_fac, label='ALS Fac Sim')\n",
        "    ax2.plot(rhos, ortho_fac, label='Ortho-ALS Fac Sim')\n",
        "    ax2.legend()\n",
        "    ax2.set_xlabel('rho')\n",
        "    ax2.set_ylabel('Avg Cosine Similarity')\n",
        "    ax2.set_title('Factor Similarity vs rho')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('exp1.png')\n",
        "    plt.show()\n",
        "\n",
        "# Experiment 2: Noise Floor\n",
        "def experiment2(d=20, k=3, rho=0, num_reps=50):\n",
        "    sigmas = np.logspace(-3, 0, 10)\n",
        "    jenn_rec = []\n",
        "    als_rec = []\n",
        "    ortho_rec = []\n",
        "    jenn_fac = []\n",
        "    als_fac = []\n",
        "    ortho_fac = []\n",
        "    for sigma in sigmas:\n",
        "        rec_j, fac_j, rec_a, fac_a = [], [], [], [] \n",
        "        rec_o, fac_o = [], []\n",
        "        for _ in range(num_reps):\n",
        "            T, T_noisy, A_true, B_true, C_true = generate_data_gmm(d, k, sigma, rho)\n",
        "            A_hat, B_hat, C_hat = jennrich(T_noisy, k)\n",
        "            if A_hat is not None:\n",
        "                hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "                rec_j.append(reconstruction_error(T, hat_T))\n",
        "                fac_j.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "            A_hat, B_hat, C_hat = cp_als(T_noisy, k)\n",
        "            hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "            rec_a.append(reconstruction_error(T, hat_T))\n",
        "            fac_a.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "            A_hat, B_hat, C_hat = ortho_als(T_noisy, k)\n",
        "            hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "            rec_o.append(reconstruction_error(T, hat_T))\n",
        "            fac_o.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "        jenn_rec.append(np.mean(rec_j) if rec_j else np.nan)\n",
        "        als_rec.append(np.mean(rec_a))\n",
        "        ortho_rec.append(np.mean(rec_o))\n",
        "        jenn_fac.append(np.mean(fac_j) if fac_j else np.nan)\n",
        "        als_fac.append(np.mean(fac_a))\n",
        "        ortho_fac.append(np.mean(fac_o))\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    ax1.plot(sigmas, jenn_rec, label='Jennrich Rec Err')\n",
        "    ax1.plot(sigmas, als_rec, label='ALS Rec Err')\n",
        "    ax1.plot(sigmas, ortho_rec, label='Ortho-ALS Rec Err')\n",
        "    ax1.legend()\n",
        "    ax1.set_xscale('log')\n",
        "    ax1.set_xlabel('sigma')\n",
        "    ax1.set_ylabel('Reconstruction Error')\n",
        "    ax1.set_title('Reconstruction Error vs sigma')\n",
        "\n",
        "    ax2.plot(sigmas, jenn_fac, label='Jennrich Fac Sim')\n",
        "    ax2.plot(sigmas, als_fac, label='ALS Fac Sim')\n",
        "    ax2.plot(sigmas, ortho_fac, label='Ortho-ALS Fac Sim')\n",
        "    ax2.legend()\n",
        "    ax2.set_xscale('log')\n",
        "    ax2.set_xlabel('sigma')\n",
        "    ax2.set_ylabel('Avg Cosine Similarity')\n",
        "    ax2.set_title('Factor Similarity vs sigma')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('exp2.png')\n",
        "    plt.show()\n",
        "\n",
        "# Experiment 3: Initialization Sensitivity\n",
        "def experiment3(d=20, k=3, sigma=0.1, rho=0.5, num_inits=20, num_reps=20):\n",
        "    var_j_rec, var_a_rec, var_j_fac, var_a_fac = [], [], [], [] \n",
        "    var_o_rec, var_o_fac = [], []\n",
        "    for _ in range(num_reps):\n",
        "        T, T_noisy, A_true, B_true, C_true = generate_data_gmm(d, k, sigma, rho)\n",
        "        # Jennrich\n",
        "        rec_js, fac_js = [], []\n",
        "        for _ in range(num_inits):\n",
        "            A_hat, B_hat, C_hat = jennrich(T_noisy, k)\n",
        "            if A_hat is not None:\n",
        "                hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "                rec_js.append(reconstruction_error(T, hat_T))\n",
        "                fac_js.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "        var_j_rec.append(np.std(rec_js) if rec_js else np.nan)\n",
        "        var_j_fac.append(np.std(fac_js) if fac_js else np.nan)\n",
        "        # ALS\n",
        "        rec_as, fac_as = [], []\n",
        "        for _ in range(num_inits):\n",
        "            A_hat, B_hat, C_hat = cp_als(T_noisy, k)\n",
        "            hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "            rec_as.append(reconstruction_error(T, hat_T))\n",
        "            fac_as.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "        var_a_rec.append(np.std(rec_as))\n",
        "        var_a_fac.append(np.std(fac_as))\n",
        "        # Ortho-ALS\n",
        "        rec_os, fac_os = [], []\n",
        "        for _ in range(num_inits):\n",
        "            A_hat, B_hat, C_hat = ortho_als(T_noisy, k)\n",
        "            hat_T = reconstruct_tensor(A_hat, B_hat, C_hat)\n",
        "            rec_os.append(reconstruction_error(T, hat_T))\n",
        "            fac_os.append((factor_recovery_error(A_true, A_hat) + factor_recovery_error(B_true, B_hat) + factor_recovery_error(C_true, C_hat)) / 3)\n",
        "        var_o_rec.append(np.std(rec_os))\n",
        "    print('Mean STD Jennrich Rec Err:', np.nanmean(var_j_rec))\n",
        "    print('Mean STD ALS Rec Err:', np.nanmean(var_a_rec))\n",
        "    print('Mean STD Ortho-ALS Rec Err:', np.nanmean(var_o_rec))\n",
        "    print('Mean STD Jennrich Fac Sim:', np.nanmean(var_j_fac))\n",
        "    print('Mean STD ALS Fac Sim:', np.nanmean(var_a_fac))\n",
        "    print('Mean STD Ortho-ALS Fac Sim:', np.nanmean(var_o_fac))\n",
        "\n",
        "# Run experiments\n",
        "experiment1()\n",
        "experiment2()\n",
        "experiment3()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
